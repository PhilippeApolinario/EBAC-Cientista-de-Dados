{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c3002e",
   "metadata": {},
   "source": [
    "# Módulo 23 - Tarefa 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae310a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a77fc",
   "metadata": {},
   "source": [
    "O Random Forest é uma técnica de aprendizado em conjunto, assim como o Bagging, que é utilizada para tarefas de classificação, regressão e outras. Seu funcionamento é baseado na criação de diversas árvores de decisão.\n",
    "\n",
    "Quando se utiliza uma única árvore de decisão com grande profundidade, há uma tendência de que a mesma aprenda padrões específicos dos dados de treinamento, o que pode resultar em um overfitting. O Random Forest é uma maneira de lidar com este problema, permitindo que sejam criadas várias árvores com grande profundidade, treinadas em diferentes partes do conjunto de treinamento. A partir daí, uma média é calculada entre elas, com o objetivo de reduzir a variância do modelo.\n",
    "\n",
    "Dessa forma, o Random Forest é uma técnica útil para lidar com problemas de overfitting e para melhorar a performance de modelos de aprendizado de máquina em geral. Além disso, ele apresenta a vantagem de ser relativamente fácil de implementar e de ser capaz de lidar com uma grande variedade de tipos de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86405d4",
   "metadata": {},
   "source": [
    "### Passo a Passo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfb44d",
   "metadata": {},
   "source": [
    "#### Feature Bagging\n",
    "\n",
    "O algoritmo de treinamento para a Random Forest aplica a técnica geral do Bootstrap Aggregating (Bagging) com uma pequena modificação dividindo também as colunas com as variáveis explicativas do modelo.\n",
    "Dado uma base treinamento $D$ com $p$ colunas de variáveis explicativas $Xi$ e uma coluna com a variável resposta $Y$, iremos gerar $m$ novas bases de dados $Di$ com $\\sqrt[2]{p}$ (arredondado para baixo) colunas de variáveis explicativas para um problema de classificação ou $p/3$ (arredondado para baixo) colunas de variáveis explicativas para um problema de regressão, recomenda-se também um tamanho mínimo de nó de valor 5.\n",
    "As colunas de variáveis explicativas devem ser selecionadas aleatóriamente e as linhas para as novas bases de dados de treino devem ser selecionadas da base de treino original de maneira aleatóriamente e com reposição."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afacce83",
   "metadata": {},
   "source": [
    "#### Modelagem\n",
    "\n",
    "Depois de criadas as bases de treino $Di$ aplicamos o método de aprendizado de árvore (Árvore de Decisão) a cada uma das $m$ bases de treino $Di$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae247ddf",
   "metadata": {},
   "source": [
    "#### Resultado\n",
    "\n",
    "Depois de ajustarmos $m$ modelos utilizando as $m$ amostras obtidas no Feature Bagging, combinamos os resultados por sua média (para modelos de regressão) ou por votação (para modelos de classificação)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f5859",
   "metadata": {},
   "source": [
    "### Diferença entre Bagging e Random Forest\n",
    "\n",
    "O Bagging é uma técnica de ensemble que cria múltiplos modelos independentes, enquanto a Random Forest é uma variação do Bagging que usa árvores de decisão como modelo base e usa amostragem aleatória dos recursos e do conjunto de dados de treinamento para reduzir a correlação entre as árvores. Ambas as técnicas são eficazes em melhorar a precisão do modelo e reduzir o overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc89e6",
   "metadata": {},
   "source": [
    "### Implementando Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568aca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77155eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    # Ajusta o modelo correspondente\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        return self\n",
    "    # Retorna previsão do modelo correspondente\n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        pass\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7473334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data_frame: pd.DataFrame, n_trees: int, n_cols: int) -> list[pd.DataFrame]:\n",
    "    return [\n",
    "        data_frame\n",
    "        .sample(frac=1.0, replace=True)\n",
    "        .sample(n_cols, axis=1) \n",
    "        for i in range(n_trees)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94832ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(samples: list[pd.DataFrame], trees: list[DecisionTree]) -> list[DecisionTree]:\n",
    "    return [tree.fit(sample) for (sample, tree) in zip(samples, trees)]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d44561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(trees: list[DecisionTree], X: pd.DataFrame) -> pd.Series:\n",
    "    predictions = [tree.predict(X) for tree in trees]\n",
    "    pred_len = len(predictions[0])\n",
    "    final_pred = pd.Series( np.zeros(pred_len) )\n",
    "    for pred in predictions:\n",
    "        final_pred += pred\n",
    "    final_pred /= len(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
